{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1facb144-cacf-486a-a7f5-1127c2d18c5d",
   "metadata": {},
   "source": [
    "Test to see how well the Levenshtein distance can be used as a predictor for relevant datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d74569a-b4e6-4315-a66c-b5aa4e1b5b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T14:08:40.219059Z",
     "start_time": "2023-09-28T14:08:40.216980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "from Bio.SubsMat.MatrixInfo import blosum62\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Create a new blosum matrix that has both directions. \n",
    "SYMMETRIC_BLOSUM = {}\n",
    "for (aa1, aa2), score in blosum62.items():\n",
    "    SYMMETRIC_BLOSUM[(aa1, aa2)] = score\n",
    "    SYMMETRIC_BLOSUM[(aa2, aa1)] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54545b8b-5a4d-405e-a0f3-bdc0913d6bf3",
   "metadata": {},
   "source": [
    "# General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fed3b6c5-fb1f-47f8-8a4d-d790763b73d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T14:08:40.839323Z",
     "start_time": "2023-09-28T14:08:40.837906Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_task(task_filename, reference_seq):\n",
    "    \n",
    "    # Load the task file and filter to just the test data\n",
    "    task_df = pd.read_csv(task_filename)\n",
    "    task_df = task_df.loc[task_df.set == \"test\"].copy()\n",
    "\n",
    "    # Create output arrays\n",
    "    refseq_len = len(reference_seq)\n",
    "    all_seqs = task_df.sequence.tolist()\n",
    "    levenshteins = np.empty(len(all_seqs))\n",
    "    blosum_scores = np.empty(len(all_seqs))\n",
    "    \n",
    "    # Calculate levenshtein distance between each sequence and the reference\n",
    "    levenshteins = np.array([levenshtein_distance(reference_seq, new_seq) \n",
    "                             for new_seq in task_df.sequence.values])\n",
    "    \n",
    "    # Calculate scores for each sequence    \n",
    "    calculate_blosum = True\n",
    "    for i, new_seq in enumerate(all_seqs):\n",
    "\n",
    "        # Score by levenshtein\n",
    "        levenshteins[i] = levenshtein_distance(reference_seq, new_seq)\n",
    "        \n",
    "        # Continue to calculate blosum unless the data is not aligned\n",
    "        if calculate_blosum:\n",
    "            \n",
    "            # Make sure the reference sequence and this sequence align\n",
    "            seqs_aligned = len(new_seq) == refseq_len\n",
    "            if not seqs_aligned:\n",
    "                calculate_blosum = False\n",
    "                blosum_scores = None\n",
    "                continue\n",
    "            \n",
    "            # Calculate blosum scores\n",
    "            blosum_scores[i] = sum(SYMMETRIC_BLOSUM[(aa1, aa2)] for \n",
    "                                   aa1, aa2 in zip(reference_seq, new_seq))\n",
    "\n",
    "    # Now get spearman rho and record. Negative levenshtein because we\n",
    "    # expect a smaller distance to be correlated to larger fitness.\n",
    "    l_rho, _ = spearmanr(-levenshteins, task_df.target.values)\n",
    "    if blosum_scores is not None:\n",
    "        b_rho, _ = spearmanr(blosum_scores, task_df.target.values)\n",
    "    else:\n",
    "        b_rho = None\n",
    "    \n",
    "    return l_rho, b_rho\n",
    "\n",
    "def evaluate_tasks(refseq_fileloc, taskfolder, task_to_file_dict):\n",
    "    \n",
    "    # Get the reference sequence\n",
    "    reference_seq = str(next(SeqIO.parse(refseq_fileloc, \"fasta\")).seq)\n",
    "\n",
    "    # Loop over each task\n",
    "    results = [[\"Task\", \"Levenshtein Rho\", \"BLOSUM62 Rho\"]]\n",
    "    for taskname, taskfile in task_to_file_dict.items():\n",
    "        rhos = evaluate_task(os.path.join(taskfolder, taskfile), \n",
    "                            reference_seq)\n",
    "        results.append([taskname, *rhos])\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d344c-51e1-4410-8bf2-2dfedfae27d4",
   "metadata": {},
   "source": [
    "# AAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a27cb5e-37fc-4b4c-9f85-405fbd65ce8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T14:08:46.743318Z",
     "start_time": "2023-09-28T14:08:41.592212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[['Task', 'Levenshtein Rho', 'BLOSUM62 Rho'],\n ['two_vs_many', 0.5776311422394775, None],\n ['seven_vs_many', 0.550377598162819, None],\n ['low_vs_high', 0.2506663869079836, None]]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein_to_fitness_aav():\n",
    "\n",
    "    # Define the different aav inputs\n",
    "    aav_refseq_file = \"./data/FLIP/aav/P03135.fasta\"\n",
    "    aav_taskfolder = \"./data/FLIP/aav/splits\"\n",
    "    aav_task_to_file = {\n",
    "        \"two_vs_many\": \"two_vs_many.csv\",\n",
    "        \"seven_vs_many\": \"seven_vs_many.csv\",\n",
    "        \"low_vs_high\": \"low_vs_high.csv\"\n",
    "    }\n",
    "\n",
    "    return evaluate_tasks(aav_refseq_file,\n",
    "                          aav_taskfolder,\n",
    "                          aav_task_to_file)\n",
    "\n",
    "levenshtein_to_fitness_aav()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7f2e3-9129-4ac7-ad0d-f0ba29c448f2",
   "metadata": {},
   "source": [
    "# GB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63a23f70-da19-4172-91ab-45767de6654b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T14:08:47.353172Z",
     "start_time": "2023-09-28T14:08:46.732068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[['Task', 'Levenshtein Rho', 'BLOSUM62 Rho'],\n ['two_vs_rest', 0.15567498369768723, 0.12831594743289912],\n ['three_vs_rest', -0.06920804785431008, 0.00486406694071143],\n ['low_vs_high', -0.10779246349106573, -0.1271557890096999]]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein_to_fitness_gb1():\n",
    "    \n",
    "    # Define the inputs\n",
    "    refseq_file = \"./data/FLIP/gb1/5LDE_1.fasta\"\n",
    "    taskfolder = \"./data/FLIP/gb1/splits\"\n",
    "    task_to_file = {\n",
    "        \"two_vs_rest\": \"two_vs_rest.csv\",\n",
    "        \"three_vs_rest\": \"three_vs_rest.csv\",\n",
    "        \"low_vs_high\": \"low_vs_high.csv\"\n",
    "    }\n",
    "    \n",
    "    return evaluate_tasks(refseq_file,\n",
    "                          taskfolder,\n",
    "                          task_to_file)\n",
    "\n",
    "levenshtein_to_fitness_gb1()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fluorescence"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12fb968b6326048a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # write string to .fasta file\n",
    "# def write_fasta(file_name, sequence, description=\"\"):\n",
    "#     with open(file_name, \"w\") as fasta_file:\n",
    "#         fasta_file.write(f\">{description}\\n\")\n",
    "#         # Split the sequence into lines of 80 characters each\n",
    "#         for i in range(0, len(sequence), 80):\n",
    "#             fasta_file.write(sequence[i:i + 80] + \"\\n\")\n",
    "# \n",
    "# # Example usage:\n",
    "# fasta_file_name = \"../data/PEER/fluorescence/wt_sequence.fasta\"\n",
    "# sequence_description = \"Wild type Sequence\"\n",
    "# # sequence_data = \"ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG\"\n",
    "# \n",
    "# write_fasta(fasta_file_name, wt_sequence, sequence_description)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37af1d4112ebc4a8"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def evaluate_task_fluorescence(task_filename, reference_seq):\n",
    "    \n",
    "    # Load the task file and filter to just the test data\n",
    "    task_df = pd.read_csv(task_filename)\n",
    "    task_df = task_df.loc[task_df.set == \"test\"].copy()\n",
    "\n",
    "    # Create output arrays\n",
    "    refseq_len = len(reference_seq)\n",
    "    # all_seqs = task_df.sequence.tolist()\n",
    "    all_seqs = task_df.primary.tolist()\n",
    "    levenshteins = np.empty(len(all_seqs))\n",
    "    blosum_scores = np.empty(len(all_seqs))\n",
    "    \n",
    "    # Calculate levenshtein distance between each sequence and the reference\n",
    "    # levenshteins = np.array([levenshtein_distance(reference_seq, new_seq) \n",
    "    #                          for new_seq in task_df.sequence.values])\n",
    "    levenshteins = np.array([levenshtein_distance(reference_seq, new_seq) \n",
    "                             for new_seq in task_df.primary.values])\n",
    "    \n",
    "    # Calculate scores for each sequence    \n",
    "    calculate_blosum = True\n",
    "    for i, new_seq in enumerate(all_seqs):\n",
    "\n",
    "        # Score by levenshtein\n",
    "        levenshteins[i] = levenshtein_distance(reference_seq, new_seq)\n",
    "        \n",
    "        # Continue to calculate blosum unless the data is not aligned\n",
    "        if calculate_blosum:\n",
    "            \n",
    "            # Make sure the reference sequence and this sequence align\n",
    "            seqs_aligned = len(new_seq) == refseq_len\n",
    "            if not seqs_aligned:\n",
    "                calculate_blosum = False\n",
    "                blosum_scores = None\n",
    "                continue\n",
    "            \n",
    "            # Calculate blosum scores\n",
    "            blosum_scores[i] = sum(SYMMETRIC_BLOSUM[(aa1, aa2)] for \n",
    "                                   aa1, aa2 in zip(reference_seq, new_seq))\n",
    "\n",
    "    # Now get spearman rho and record. Negative levenshtein because we\n",
    "    # expect a smaller distance to be correlated to larger fitness.\n",
    "    # l_rho, _ = spearmanr(-levenshteins, task_df.target.values)\n",
    "    l_rho, _ = spearmanr(-levenshteins, task_df.log_fluorescence.values)\n",
    "    if blosum_scores is not None:\n",
    "        b_rho, _ = spearmanr(blosum_scores, task_df.target.values)\n",
    "    else:\n",
    "        b_rho = None\n",
    "    \n",
    "    return l_rho, b_rho\n",
    "\n",
    "def evaluate_tasks_fluorescence(refseq_fileloc, taskfolder, task_to_file_dict):\n",
    "    \n",
    "    # Get the reference sequence\n",
    "    reference_seq = str(next(SeqIO.parse(refseq_fileloc, \"fasta\")).seq)\n",
    "\n",
    "    # Loop over each task\n",
    "    results = [[\"Task\", \"Levenshtein Rho\", \"BLOSUM62 Rho\"]]\n",
    "    for taskname, taskfile in task_to_file_dict.items():\n",
    "        rhos = evaluate_task_fluorescence(os.path.join(taskfolder, taskfile), \n",
    "                            reference_seq)\n",
    "        results.append([taskname, *rhos])\n",
    "        \n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T14:08:33.605597Z",
     "start_time": "2023-09-28T14:08:33.560538Z"
    }
   },
   "id": "df8945d5a0155680"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[['Task', 'Levenshtein Rho', 'BLOSUM62 Rho'],\n ['two_vs_rest', 0.46596018330742606, None],\n ['three_vs_rest', 0.05396761248845623, None],\n ['low_vs_high', 0.011234704728670488, None]]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein_to_fitness_fluorescence():\n",
    "    \n",
    "    # Define the inputs\n",
    "    refseq_file = \"./data/PEER/fluorescence/wt_sequence.fasta\"\n",
    "    taskfolder = \"./data/PEER/fluorescence/splits\"\n",
    "    task_to_file = {\n",
    "        \"two_vs_rest\": \"two_vs_many.csv\",\n",
    "        \"three_vs_rest\": \"seven_vs_many.csv\",\n",
    "        \"low_vs_high\": \"low_vs_high.csv\"\n",
    "    }\n",
    "    \n",
    "    return evaluate_tasks_fluorescence(refseq_file,\n",
    "                          taskfolder,\n",
    "                          task_to_file)\n",
    "\n",
    "levenshtein_to_fitness_fluorescence()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T14:08:34.622955Z",
     "start_time": "2023-09-28T14:08:33.900437Z"
    }
   },
   "id": "e8fa3a0c7e4915b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "decb600f30766355"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
